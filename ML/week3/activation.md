
### *Activation function*

### 정의
  - 뉴럴 네트워크의 개별 뉴런에 들어오는 입력신호의 총합을 출력신호로 변환하는 함수를 활성화 함수라고 합니다. 활성화 함수 유무는 초창기 모델일 퍼셉트론과 뉴럴네트워크의 유일한 차이점이기도 한다. 
  - 활성화 함수는 대개 비선형 함수 (non-linear function)를 사용합니다.
  - 선형 함수를 사용하지 않는 이유는? 
  > *선형 함수인 h(x)= cx 를 활성화 함수로 사용한 3 층 네트워크를 떠올려 보세요. 이를 식으로 나타내면 y(x)=h(h(h(x)))가 됩니다. 이는 실은 y(x)=ax와 똑같은 식입니다. a=c^3이라고만 하면 끄이죠. 즉, 은닉층이 없는 네트워크로 표현할 수 있습니다. 뉴럴네트워크에서 층을 쌓는 혜택을 얻고 싶다면 활성화함수로는 반드시 비션형 함수를 사용해야 합니다. <'밑바닥부터 시작하는 >*
